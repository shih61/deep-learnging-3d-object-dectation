{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet Model\n",
    "In this notebook, we develop the Pyramid Scene Parsing network (based on https://github.com/Lextal/pspnet-pytorch), along with ResNet pretrainerd model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Disable multiprocesing for numpy/opencv. We already multiprocess ourselves, this would mean every subprocess produces\n",
    "# even more threads which would lead to a lot of context switching, slowing things down a lot.\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import scipy.special\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "from lyft_dataset_sdk.eval.detection.mAP_evaluation import Box3D\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"car\", \"motorcycle\", \"bus\", \"bicycle\", \"truck\", \"pedestrian\", \"other_vehicle\", \"animal\", \"emergency_vehicle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits\n",
    "# Model implementation based on https://github.com/Lextal/pspnet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Here is some code for augmenting data. We are not using this yet, but we believe scaling, cropping, padding, changing color hues would be a great way to extend the data and improve model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numbers\n",
    "import math\n",
    "import collections\n",
    "\n",
    "from PIL import ImageOps, Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Padding:\n",
    "    def __init__(self, pad):\n",
    "        self.pad = pad\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return ImageOps.expand(img, border=self.pad, fill=0)\n",
    "\n",
    "\n",
    "class Scale:\n",
    "    def __init__(self, size, interpolation=Image.NEAREST):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        img, target = imgmap\n",
    "        if isinstance(self.size, int):\n",
    "            w, h = img.size\n",
    "            if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "                return img, target\n",
    "            if w < h:\n",
    "                ow = self.size\n",
    "                oh = int(self.size * h / w)\n",
    "                return img.resize((ow, oh), self.interpolation), target.resize((ow, oh), self.interpolation)\n",
    "            else:\n",
    "                oh = self.size\n",
    "                ow = int(self.size * w / h)\n",
    "                return img.resize((ow, oh), self.interpolation), target.resize((ow, oh), self.interpolation)\n",
    "        else:\n",
    "            return img.resize(self.size, self.interpolation), target.resize(self.size, self.interpolation)\n",
    "\n",
    "\n",
    "class CenterCrop:\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        img, target = imgmap\n",
    "        w, h = img.size\n",
    "        th, tw = self.size\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th)), target.crop((x1, y1, x1 + tw, y1 + th))\n",
    "\n",
    "\n",
    "class RandomCrop:\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        img, target = imgmap\n",
    "        w, h = img.size\n",
    "        if self.size is not None:\n",
    "            th, tw = self.size\n",
    "            if w == tw and h == th:\n",
    "                return img, target\n",
    "            else:\n",
    "                x1 = random.randint(0, w - tw)\n",
    "                y1 = random.randint(0, h - th)\n",
    "            return img.crop((x1, y1, x1 + tw, y1 + th)), target.crop((x1, y1, x1 + tw, y1 + th))\n",
    "        else:\n",
    "            return img, target\n",
    "\n",
    "\n",
    "class RandomSizedCrop:\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.NEAREST):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        img, target = imgmap\n",
    "        for attempt in range(10):\n",
    "            area = img.size[0] * img.size[1]\n",
    "            target_area = random.uniform(0.5, 1.0) * area\n",
    "            aspect_ratio = random.uniform(3. / 4, 4. / 3)\n",
    "\n",
    "            w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                w, h = h, w\n",
    "\n",
    "            if w <= img.size[0] and h <= img.size[1]:\n",
    "                x1 = random.randint(0, img.size[0] - w)\n",
    "                y1 = random.randint(0, img.size[1] - h)\n",
    "\n",
    "                img = img.crop((x1, y1, x1 + w, y1 + h))\n",
    "                target = target.crop((x1, y1, x1 + w, y1 + h))\n",
    "                assert(img.size == (w, h))\n",
    "                assert(target.size == (w, h))\n",
    "\n",
    "                return img.resize((self.size, self.size), self.interpolation), \\\n",
    "                       target.resize((self.size, self.size), self.interpolation)\n",
    "\n",
    "        # Fallback\n",
    "        scale = Scale(self.size, interpolation=self.interpolation)\n",
    "        crop = CenterCrop(self.size)\n",
    "        return crop(scale((img, target)))\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip:\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        img, target = imgmap\n",
    "        if random.random() < 0.5:\n",
    "            return img.transpose(Image.FLIP_LEFT_RIGHT), target.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return img, target\n",
    "\n",
    "\n",
    "class RandomRotation:\n",
    "\n",
    "    def __call__(self, imgmap, degree=10):\n",
    "        img, target = imgmap\n",
    "        deg = np.random.randint(-degree, degree, 1)[0]\n",
    "        return img.rotate(deg), target.rotate(deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "We have already prepared our dataset. For local training and testing, we have split our training set to about 70/30, into training and validation. This allows us to validate our results locally and have a smaller dataset to train against.\n",
    "\n",
    "Once we are certain, we will train our model on the full dataset for Kaggke submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 10.5 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 4.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "classes = [\"car\", \"motorcycle\", \"bus\", \"bicycle\", \"truck\", \"pedestrian\", \"other_vehicle\", \"animal\", \"emergency_vehicle\"]\n",
    "level5data = LyftDataset(data_path='/home/ys3152/train_dataset', json_path='/home/ys3152/train_data', verbose=True)\n",
    "class_heights = {'animal':0.51,'bicycle':1.44,'bus':3.44,'car':1.72,'emergency_vehicle':2.39,'motorcycle':1.59,\n",
    "                'other_vehicle':3.23,'pedestrian':1.78,'truck':3.44}\n",
    "# ARTIFACTS_FOLDER = \"/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/\"\n",
    "ARTIFACTS_FOLDER = \"/home/hsb2140/artifacts/\"\n",
    "data_folder = os.path.join(ARTIFACTS_FOLDER, \"bev_train_data\")\n",
    "#level5data = LyftDataset(data_path='/home/ys3152/test_dataset', json_path='/home/ys3152/test_data', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [(level5data.get('sample', record['first_sample_token'])['timestamp'], record) for record in level5data.scene]\n",
    "\n",
    "entries = []\n",
    "\n",
    "for start_time, record in sorted(records):\n",
    "    start_time = level5data.get('sample', record['first_sample_token'])['timestamp'] / 1000000\n",
    "\n",
    "    token = record['token']\n",
    "    name = record['name']\n",
    "    date = datetime.utcfromtimestamp(start_time)\n",
    "    host = \"-\".join(record['name'].split(\"-\")[:2])\n",
    "    first_sample_token = record[\"first_sample_token\"]\n",
    "\n",
    "    entries.append((host, name, date, token, first_sample_token))\n",
    "            \n",
    "df = pd.DataFrame(entries, columns=[\"host\", \"scene_name\", \"date\", \"scene_token\", \"first_sample_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 40 train/validation split scene counts\n"
     ]
    }
   ],
   "source": [
    "validation_hosts = [\"host-a007\", \"host-a008\", \"host-a009\"]\n",
    "\n",
    "validation_df = df[df[\"host\"].isin(validation_hosts)]\n",
    "vi = validation_df.index\n",
    "train_df = df[~df.index.isin(vi)]\n",
    "\n",
    "print(len(train_df), len(validation_df), \"train/validation split scene counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9566a2d753404ff78e06c2295812bac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=140), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of tokens= 17640\n"
     ]
    }
   ],
   "source": [
    "# sample_sub = pd.read_csv('../input/3d-object-detection-for-autonomous-vehicles/sample_submission.csv')\n",
    "all_sample_tokens,scene_len = [],[]\n",
    "for sample_token in tqdm_notebook(train_df.first_sample_token.values):\n",
    "    i = 0\n",
    "    while sample_token:\n",
    "        all_sample_tokens.append(sample_token)\n",
    "        sample = level5data.get(\"sample\", sample_token)\n",
    "        sample_token = sample[\"next\"]\n",
    "        i += 1\n",
    "    scene_len.append(i)\n",
    "#     print(len(all_sample_tokens[-1]))\n",
    "    \n",
    "print('Total number of tokens=',len(all_sample_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAFQCAAAAADMg3kFAAAFHUlEQVR4Ae3BQW7jCBZEwfcW9v3P61n8lgciiwYoWyZSXVIzI6SipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKLkJtkY6i5yk2wMd5Cr4Sa5GH4gn4ZbZGN4InKTbAx3kKthh6yGH8hq2CEbwxORm2RjuINcDTtkNfxAVsMO2RieiNwkG8Md5GrYIavhB7IY9sjG8ETkXyOr4QeyGPbIxvBE5F8jn4a7ycXwWqSipKKkoiRBNoYdshj+Y2QxgCTIxrBDFsMuWQ0ZshoeRxYDSIJsDDtkMeyS1ZAhq+FxZDGAJMjGsEMWwy5ZDRmyGh5HFgNIgmwMO2Qx7JLVkCGr4XFkMYD8d8lq+LdIRUlFyffkj6F+JN+TP4bb5Go4QhbDLbIa7iaL4R6yGI6Q78kfw21yNRwhi+EWWQ13k8VwD1kMR8j35I/hNrkajpDFcIushrvJYriHLIYj5Hvyx3CbXA1HyGK4RVbD3WQx3EMWwxGSIVfDc5HFcA9ZDEdIRUlFyYPJ1fAIshh+IIvh9+Rq+JY8mFwNt8li+B1ZDD+QxfB7cjV8Sx5MrobbZDHsktWwJYvhB7IYfk+uhm/Jg8nVcJsshl2yGrZkMfxAFsPvydXwLXkGshh2yWo4SBbD78nV8C15CbIanppUlFSU/DWyMWTIavgb5K+RjSFDVsNXshgeR/4a2RgyZDV8JYvhceSvkY0hQ1bDV7IYHkf+GtkYMmQ1fCWL4XHkXORieBypKKkoqSipKKkoqSg5N4csOTVhiJIzk4shSU5M/m8IkjOTT8MBsho25NTk0/B7sho25Nzk0/Brsho25OTk0/Bbsho25OwEhl+T1bAhp+cQJBUlddQbq/+xkDrqjR1SR72xQ+qoN3ZIHfXGDqmj3tghddQbO6SOemOHVJRUlFSUVJRUlFSUVJRUlFSURMlqOCWJktVwShIlq+GUJEpWwylJlKyGU5IHkIvhlKSipKLk9ASGFDk9gSFFnt47HzySwJAiz+4dPngkgSFFnt/7B48kMKTI2cnFkCJnJxdDipydXAxfvMMHx8jZycXwxTsfHCRnJxfDV+8fHCQVJRUlT0sYXo48LbkYXow8LbkYXow8K/k0vBh5VnIxvBp5VnIxvBp5VnIxvBp5UvJpeDXypORieDnypORieDnyvGR4OVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJR/wCGUal0L/bpkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize\n",
    "folder = \"/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/bev_train_data\"\n",
    "input_filepath = sorted(glob.glob(os.path.join(folder, \"*_input.png\")))[0]\n",
    "map_fp = sorted(glob.glob(os.path.join(folder, \"*map.png\")))[0]\n",
    "target_fp = sorted(glob.glob(os.path.join(folder, \"*_target.png\")))[0]\n",
    "\n",
    "listOfImageNames = [input_filepath, map_fp, target_fp]\n",
    "\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/bev_train_data\n",
      "17640\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "# class BEVImageDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, sample_tokens, data_folder, is_train=True, ignore_map=True):\n",
    "#         self.is_train = is_train\n",
    "#         self.sample_tokens = sample_tokens\n",
    "#         self.data_folder = data_folder\n",
    "#         self.ignore_map = ignore_map\n",
    "#     def __len__(self):\n",
    "#         return len(self.sample_tokens)\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         sample_token = self.sample_tokens[idx]\n",
    "#         # Get file path, assuming data already preprocessed and stored in data_folder\n",
    "#         input_filepath = os.path.join(self.data_folder,f\"{sample_token}_input.png\")\n",
    "        \n",
    "#         target = None\n",
    "# #         if self.is_train:\n",
    "#         target_filepath = os.path.join(self.data_folder,f\"{sample_token}_target.png\")\n",
    "#         target = cv2.imread(target_filepath, cv2.IMREAD_UNCHANGED)\n",
    "#         if target is None:\n",
    "#             print()\n",
    "#         target = target.astype(np.int64)\n",
    "#         target = torch.from_numpy(target)\n",
    "        \n",
    "#         im = cv2.imread(input_filepath, cv2.IMREAD_UNCHANGED)\n",
    "# #         if not self.ignore_map:\n",
    "# #             map_filepath = os.path.join(self.data_folder,f\"{sample_token}_map.png\")\n",
    "# #             map_im = cv2.imread(map_filepath, cv2.IMREAD_UNCHANGED)\n",
    "# #             # Concatenate image and map for network input\n",
    "# #             im = np.concatenate((im, map_im), axis=2)\n",
    "#         im = im.astype(np.float32)/255\n",
    "#         im = torch.from_numpy(im.transpose(2,0,1))\n",
    "        \n",
    "#         if target is None:\n",
    "#             print(sample_token, target_filepath)\n",
    "        \n",
    "# #         if not self.is_train:\n",
    "# #             return im, sample_token\n",
    "# #         else:\n",
    "#         return im, target, sample_token\n",
    "\n",
    "class BEVImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_filepaths, target_filepaths, map_filepaths=None):\n",
    "        self.input_filepaths = input_filepaths\n",
    "        self.target_filepaths = target_filepaths\n",
    "        self.map_filepaths = map_filepaths\n",
    "        \n",
    "        if map_filepaths is not None:\n",
    "            assert len(input_filepaths) == len(map_filepaths)\n",
    "        \n",
    "        assert len(input_filepaths) == len(target_filepaths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_filepath = self.input_filepaths[idx]\n",
    "        target_filepath = self.target_filepaths[idx]\n",
    "        \n",
    "        sample_token = input_filepath.split(\"/\")[-1].replace(\"_input.png\",\"\")\n",
    "        \n",
    "        im = cv2.imread(input_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        if self.map_filepaths:\n",
    "            map_filepath = self.map_filepaths[idx]\n",
    "            map_im = cv2.imread(map_filepath, cv2.IMREAD_UNCHANGED)\n",
    "            im = np.concatenate((im, map_im), axis=2)\n",
    "        \n",
    "        target = cv2.imread(target_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        im = im.astype(np.float32)/255\n",
    "        target = target.astype(np.int64)\n",
    "        \n",
    "        im = torch.from_numpy(im.transpose(2,0,1))\n",
    "        target = torch.from_numpy(target)\n",
    "        \n",
    "        return im, target, sample_token\n",
    "\n",
    "data_folder = '/home/hsb2140/artifacts/bev_train_data/'\n",
    "input_filepaths = sorted(glob.glob(os.path.join(data_folder, \"*_input.png\")))\n",
    "# map_filepaths = sorted(glob.glob(os.path.join(data_folder, \"*_map.png\")))\n",
    "target_filepaths = sorted(glob.glob(os.path.join(data_folder, \"*_target.png\")))\n",
    "\n",
    "# train_data_folder = '/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/bev_train_data'\n",
    "\n",
    "# Use for Local training (train/validation) split 50/50 - data already split 50/50 and stored\n",
    "# test_data_folder = '/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/test_data/test_data'\n",
    "data_folder = '/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/bev_train_data'\n",
    "print(data_folder)\n",
    "print(len(all_sample_tokens))\n",
    "batch_size=16\n",
    "# train_dataset = BEVImageDataset(all_sample_tokens, data_folder, is_train=True, ignore_map=True)\n",
    "train_dataset = BEVImageDataset(input_filepaths, target_filepaths)\n",
    "# train_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import model_zoo\n",
    "from torchvision.models.densenet import densenet121, densenet161\n",
    "from torchvision.models.squeezenet import squeezenet1_1\n",
    "\n",
    "\n",
    "def load_weights_sequential(target, source_state):\n",
    "    model_to_load= {k: v for k, v in source_state.items() if k in target.state_dict().keys()}\n",
    "    target.load_state_dict(model_to_load)\n",
    "\n",
    "'''\n",
    "    Implementation of dilated ResNet-101 with deep supervision. Downsampling is changed to 8x\n",
    "'''\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, dilation=dilation, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride=stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, stride=1, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, dilation=dilation,\n",
    "                               padding=dilation, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers=(3, 4, 23, 3)):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x_3 = self.layer3(x)\n",
    "        x = self.layer4(x_3)\n",
    "\n",
    "        return x, x_3\n",
    "\n",
    "\n",
    "'''\n",
    "    Implementation of DenseNet with deep supervision. Downsampling is changed to 8x \n",
    "'''\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                                            growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                                            kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features, downsample=True):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        if downsample:\n",
    "            self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        else:\n",
    "            self.add_module('pool', nn.AvgPool2d(kernel_size=1, stride=1))  # compatibility hack\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, pretrained=True):\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.start_features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "\n",
    "        init_weights = list(densenet121(pretrained=True).features.children())\n",
    "        start = 0\n",
    "        for i, c in enumerate(self.start_features.children()):\n",
    "            if pretrained:\n",
    "                c.load_state_dict(init_weights[i].state_dict())\n",
    "            start += 1\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            if pretrained:\n",
    "                block.load_state_dict(init_weights[start].state_dict())\n",
    "            start += 1\n",
    "            self.blocks.append(block)\n",
    "            setattr(self, 'denseblock%d' % (i + 1), block)\n",
    "\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                downsample = i < 1\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2,\n",
    "                                    downsample=downsample)\n",
    "                if pretrained:\n",
    "                    trans.load_state_dict(init_weights[start].state_dict())\n",
    "                start += 1\n",
    "                self.blocks.append(trans)\n",
    "                setattr(self, 'transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.start_features(x)\n",
    "        deep_features = None\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            out = block(out)\n",
    "            if i == 5:\n",
    "                deep_features = out\n",
    "\n",
    "        return out, deep_features\n",
    "\n",
    "\n",
    "class Fire(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, squeeze_planes,\n",
    "                 expand1x1_planes, expand3x3_planes, dilation=1):\n",
    "        super(Fire, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                                   kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                                   kernel_size=3, padding=dilation, dilation=dilation)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_activation(self.expand1x1(x)),\n",
    "            self.expand3x3_activation(self.expand3x3(x))\n",
    "        ], 1)\n",
    "\n",
    "\n",
    "class SqueezeNet(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(SqueezeNet, self).__init__()\n",
    "\n",
    "        self.feat_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.feat_2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            Fire(64, 16, 64, 64),\n",
    "            Fire(128, 16, 64, 64)\n",
    "        )\n",
    "        self.feat_3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            Fire(128, 32, 128, 128, 2),\n",
    "            Fire(256, 32, 128, 128, 2)\n",
    "        )\n",
    "        self.feat_4 = nn.Sequential(\n",
    "            Fire(256, 48, 192, 192, 4),\n",
    "            Fire(384, 48, 192, 192, 4),\n",
    "            Fire(384, 64, 256, 256, 4),\n",
    "            Fire(512, 64, 256, 256, 4)\n",
    "        )\n",
    "        if pretrained:\n",
    "            weights = squeezenet1_1(pretrained=True).features.state_dict()\n",
    "            load_weights_sequential(self, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f1 = self.feat_1(x)\n",
    "        f2 = self.feat_2(f1)\n",
    "        f3 = self.feat_3(f2)\n",
    "        f4 = self.feat_4(f3)\n",
    "        return f4, f3\n",
    "\n",
    "\n",
    "'''\n",
    "    Handy methods for construction\n",
    "'''\n",
    "\n",
    "\n",
    "def squeezenet(pretrained=True):\n",
    "    return SqueezeNet(pretrained)\n",
    "\n",
    "\n",
    "def densenet(pretrained=True):\n",
    "    return DenseNet(pretrained=pretrained)\n",
    "\n",
    "\n",
    "def resnet18(pretrained=True):\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    if pretrained:\n",
    "        load_weights_sequential(model, model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=True):\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "    if pretrained:\n",
    "        load_weights_sequential(model, model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=True):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "    if pretrained:\n",
    "        load_weights_sequential(model, model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=True):\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "    if pretrained:\n",
    "        load_weights_sequential(model, model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=True):\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "    if pretrained:\n",
    "        load_weights_sequential(model, model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n",
    "extractors = {}\n",
    "extractors['squeezenet'] = squeezenet\n",
    "extractors['densenet'] = densenet\n",
    "extractors['resnet18'] = resnet18\n",
    "extractors['resnet34'] = resnet34\n",
    "extractors['resnet50'] = resnet50\n",
    "extractors['resnet101'] = resnet101\n",
    "extractors['resnet152'] = resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class PSPModule(nn.Module):\n",
    "    def __init__(self, features, out_features=1024, sizes=(1, 2, 3, 6)):\n",
    "        super().__init__()\n",
    "        self.stages = []\n",
    "        self.stages = nn.ModuleList([self._make_stage(features, size) for size in sizes])\n",
    "        self.bottleneck = nn.Conv2d(features * (len(sizes) + 1), out_features, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _make_stage(self, features, size):\n",
    "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
    "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
    "        return nn.Sequential(prior, conv)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        h, w = feats.size(2), feats.size(3)\n",
    "        priors = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.stages] + [feats]\n",
    "        bottle = self.bottleneck(torch.cat(priors, 1))\n",
    "        return self.relu(bottle)\n",
    "\n",
    "\n",
    "class PSPUpsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = 2 * x.size(2), 2 * x.size(3)\n",
    "        p = F.upsample(input=x, size=(h, w), mode='bilinear')\n",
    "        return self.conv(p)\n",
    "\n",
    "\n",
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes=18, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet34',\n",
    "                 pretrained=False):\n",
    "        super().__init__()\n",
    "#         self.feats = getattr(extractors, backend)(pretrained)\n",
    "        self.feats = extractors[backend](pretrained)\n",
    "        self.psp = PSPModule(psp_size, 1024, sizes)\n",
    "        self.drop_1 = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        self.up_1 = PSPUpsample(1024, 256)\n",
    "        self.up_2 = PSPUpsample(256, 64)\n",
    "        self.up_3 = PSPUpsample(64, 64)\n",
    "\n",
    "        self.drop_2 = nn.Dropout2d(p=0.15)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, n_classes, kernel_size=1),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(deep_features_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f, class_f = self.feats(x) \n",
    "        p = self.psp(f)\n",
    "        p = self.drop_1(p)\n",
    "\n",
    "        p = self.up_1(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_2(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        p = self.up_3(p)\n",
    "        p = self.drop_2(p)\n",
    "\n",
    "        auxiliary = F.adaptive_max_pool2d(input=class_f, output_size=(1, 1)).view(-1, class_f.size(1))\n",
    "\n",
    "        return self.final(p), self.classifier(auxiliary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# We weigh the loss for the 0 class lower to account for (some of) the big class imbalance.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_weights = torch.from_numpy(np.array([0.2] + [1.0]*len(classes), dtype=np.float32))\n",
    "class_weights = class_weights.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from radamoptimizer import *\n",
    "\n",
    "models = {\n",
    "    'squeezenet': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=512, deep_features_size=256, backend='squeezenet'),\n",
    "    'densenet': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=1024, deep_features_size=512, backend='densenet'),\n",
    "    'resnet18': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=512, deep_features_size=256, backend='resnet18'),\n",
    "    'resnet34': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=512, deep_features_size=256, backend='resnet34'),\n",
    "    'resnet50': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet50'),\n",
    "    'resnet101': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet101'),\n",
    "    'resnet152': lambda: PSPNet(n_classes=len(classes)+1, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet152')\n",
    "}\n",
    "\n",
    "def build_network(snapshot, backend):\n",
    "    epoch = 0\n",
    "    backend = backend.lower()\n",
    "    net = models[backend]()\n",
    "    net = nn.DataParallel(net)\n",
    "    if snapshot is not None:\n",
    "        _, epoch = os.path.basename(snapshot).split('_')\n",
    "        epoch = int(epoch)\n",
    "        net.load_state_dict(torch.load(snapshot))\n",
    "        logging.info(\"Snapshot for epoch {} loaded from {}\".format(epoch, snapshot))\n",
    "    net = net.cuda()\n",
    "    return net, epoch\n",
    "\n",
    "\n",
    "backend='resnet18'\n",
    "snapshot=None\n",
    "crop_x=256 \n",
    "crop_y=256\n",
    "batch_size=16\n",
    "alpha=0.01\n",
    "epochs=20\n",
    "milestones='10,20,30'\n",
    "gpu='0'\n",
    "\n",
    "net, starting_epoch = build_network(snapshot, backend)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count()*2)\n",
    "\n",
    "'''\n",
    "    To follow this training routine you need a DataLoader that yields the tuples of the following format:\n",
    "    (Bx3xHxW FloatTensor x, BxHxW LongTensor y, BxN LongTensor y_cls) where\n",
    "    x - batch of input images,\n",
    "    y - batch of groung truth seg maps,\n",
    "    y_cls - batch of 1D tensors of dimensionality N: N total number of classes, \n",
    "    y_cls[i, T] = 1 if class T is present in image i, 0 otherwise\n",
    "'''\n",
    "train_loader, class_weights, n_images = None, None, None\n",
    "\n",
    "all_losses = []\n",
    "optim = RAdam(net.parameters(), lr=1e-3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "TODO: Model fails with current data preprocessing because data has not been preprocessed to match the input of the network. **This is a work in progress.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4da4023fa5489abc70dba77abe2e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsb2140/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:210: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "/home/hsb2140/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:2390: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/hsb2140/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/hsb2140/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.40185818\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5318a5eb23b041ffadb70e9f3295c6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.034332786\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a702f3b8f5ef44eb9ad97b419523cf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.025715081\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db14635ff87d4505b2cefd4a5a80e6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.022366265\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cf6ee81f7e461e9951535a08f44a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.020544393\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56689968f6bd4976b92fc4dfc8f16b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.019371957\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1f1b55d743491ca5312797862ed4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.018440153\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6904d9dbb723476f8c16cffbd1119f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.01775145\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb7a4a5fb34214873ee279c6f5aa4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.017030312\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abcf59a906843868e1cb84d6a00cfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.01658215\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a18c5b72304cf7a9191cea03bbbe18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.016091995\n",
      "Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef342c6c07ea40419b6ae0a86756459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.015600695\n",
      "Epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f93f63b0fef4e9d828334f5045c0051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.015272542\n",
      "Epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab60139ac37c44338008ee72e4af85c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.0148688285\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8750d1e03e934de2a54964b73c632e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.014674068\n",
      "Epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dcd7ecb7ba4bb7a54cdc65bf1bee6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1bcb8afe196c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deep-learnging-3d-object-dectation/radamoptimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    \n",
    "    progress_bar = tqdm_notebook(dataloader)\n",
    "\n",
    "    seg_criterion = nn.NLLLoss2d(weight=class_weights)\n",
    "#     cls_criterion = nn.BCEWithLogitsLoss(weight=class_weights)\n",
    "    epoch_losses = []\n",
    "    net.train()\n",
    "    for ii, (X, target, sample_ids) in enumerate(progress_bar):\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        X = X.to(device)  # [N, 3, H, W]\n",
    "        target = target.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        prediction, out_cls = net(X)  # [N, 2, H, W]\n",
    "        \n",
    "        seg_loss = seg_criterion(prediction, target) \n",
    "        #cls_loss = cls_criterion(out_cls, y_cls)\n",
    "        loss = seg_loss + alpha\n",
    "#         loss = seg_loss + alpha * cls_loss\n",
    "#         loss = F.cross_entropy(prediction, target, weight=class_weights)\n",
    "    \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        epoch_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    print(\"Loss:\", np.mean(epoch_losses))\n",
    "    all_losses.extend(epoch_losses)\n",
    "\n",
    "    checkpoint_filepath = os.path.join('/home/hsb2140/', \"seg_restnet18pspnet_checkpoint_epoch_{}.pth\".format(epoch))\n",
    "    state = {'epoch': epoch + 1, \n",
    "             'model_state_dict': net.state_dict(),\n",
    "             'optimizer_state_dict': optim.state_dict(), \n",
    "             'loss': seg_criterion }\n",
    "    torch.save(state, checkpoint_filepath)\n",
    "#     train_loss = np.mean(epoch_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5ab3aa809b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m '''\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_losses' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Loss: 0.40185818\n",
    "Epoch 1\n",
    "\n",
    "Loss: 0.034332786\n",
    "Epoch 2\n",
    "\n",
    "Loss: 0.025715081\n",
    "Epoch 3\n",
    "\n",
    "Loss: 0.022366265\n",
    "Epoch 4\n",
    "\n",
    "Loss: 0.020544393\n",
    "Epoch 5\n",
    "\n",
    "Loss: 0.019371957\n",
    "Epoch 6\n",
    "\n",
    "Loss: 0.018440153\n",
    "Epoch 7\n",
    "\n",
    "Loss: 0.01775145\n",
    "Epoch 8\n",
    "\n",
    "Loss: 0.017030312\n",
    "Epoch 9\n",
    "\n",
    "Loss: 0.01658215\n",
    "Epoch 10\n",
    "\n",
    "Loss: 0.016091995\n",
    "Epoch 11\n",
    "\n",
    "Loss: 0.015600695\n",
    "Epoch 12\n",
    "\n",
    "Loss: 0.015272542\n",
    "Epoch 13\n",
    "\n",
    "Loss: 0.0148688285\n",
    "Epoch 14\n",
    "\n",
    "Loss: 0.014674068\n",
    "Epoch 15\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [0.24649781,0.019393962,0.013151167,0.010835841, 0.009487289]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_unet_model(in_channels=6, num_output_classes=2):\n",
    "    model = UNet(in_channels=in_channels, n_classes=num_output_classes, wf=5, depth=4, padding=True, up_mode='upsample')\n",
    "    \n",
    "    # Optional, for multi GPU training and inference\n",
    "    model = nn.DataParallel(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = get_unet_model(num_output_classes=len(classes)+1)\n",
    "\n",
    "state = torch.load('/home/hsb2140/deep-learnging-3d-object-dectation//input/lyft3d-mask-test-data/unet_checkpoint_epoch_10.pth')\n",
    "model10.load_state_dict(state)\n",
    "model10 = model10.to(device)\n",
    "model10.eval();\n",
    "\n",
    "\n",
    "# model9 = get_unet_model(num_output_classes=len(classes)+1)\n",
    "\n",
    "# state = torch.load('/home/hsb2140/deep-learnging-3d-object-dectation//input/lyft3d-mask-test-data/unet_checkpoint_epoch_9.pth')\n",
    "# model9.load_state_dict(state)\n",
    "# model9 = model9.to(device)\n",
    "# model9.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def __call__(self, x_psp, x_unet):\n",
    "        res = []\n",
    "        x_unet = x_unet.cuda()\n",
    "        x_psp = x_psp.cuda()\n",
    "        with torch.no_grad():\n",
    "            psp_pred, _cls = self.models[0](x_psp)\n",
    "            unet_pred = self.models[1](x_unet)\n",
    "            res.append(psp_pred)\n",
    "            res.append(unet_pred)\n",
    "#             for m, t in self.models:\n",
    "#                 if t == 'PSP':\n",
    "#                     prediction, cls = m(x)\n",
    "#                 else:\n",
    "#                     prediction = m(x)\n",
    "#                 res.append(prediction)\n",
    "        res = torch.stack(res)\n",
    "        return torch.mean(res, dim=0)\n",
    "    \n",
    "net7, _ = build_network(None, backend)\n",
    "state = torch.load('/home/hsb2140/2_pspnet_checkpoint_epoch_7.pth')\n",
    "net7.load_state_dict(state)\n",
    "net7 = net7.to(device)\n",
    "net7.eval();\n",
    "\n",
    "# net6, _ = build_network(None, backend)\n",
    "# state = torch.load('/home/hsb2140/2_pspnet_checkpoint_epoch_6.pth')\n",
    "# net6.load_state_dict(state)\n",
    "# net6 = net6.to(device)\n",
    "# net6.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([net7,model10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_heights = {'animal':0.51,'bicycle':1.44,'bus':3.44,'car':1.72,'emergency_vehicle':2.39,'motorcycle':1.59,\n",
    "                'other_vehicle':3.23,'pedestrian':1.78,'truck':3.44}\n",
    "level5data = LyftDataset(data_path='/home/ys3152/test_dataset', json_path='/home/ys3152/test_data', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters we'll need to define for the system\n",
    "voxel_size = (0.4, 0.4, 1.5)\n",
    "z_offset = -2.0\n",
    "bev_shape = (336, 336, 3)\n",
    "\n",
    "# We scale down each box so they are more separated when projected into our coarse voxel space.\n",
    "box_scale = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [(level5data.get('sample', record['first_sample_token'])['timestamp'], record) for record in level5data.scene]\n",
    "\n",
    "entries = []\n",
    "\n",
    "for start_time, record in sorted(records):\n",
    "    start_time = level5data.get('sample', record['first_sample_token'])['timestamp'] / 1000000\n",
    "\n",
    "    token = record['token']\n",
    "    name = record['name']\n",
    "    date = datetime.utcfromtimestamp(start_time)\n",
    "    host = \"-\".join(record['name'].split(\"-\")[:2])\n",
    "    first_sample_token = record[\"first_sample_token\"]\n",
    "\n",
    "    entries.append((host, name, date, token, first_sample_token))\n",
    "            \n",
    "df = pd.DataFrame(entries, columns=[\"host\", \"scene_name\", \"date\", \"scene_token\", \"first_sample_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sub = pd.read_csv('../input/3d-object-detection-for-autonomous-vehicles/sample_submission.csv')\n",
    "all_sample_tokens,scene_len = [],[]\n",
    "for sample_token in tqdm_notebook(df.first_sample_token.values):\n",
    "    i = 0\n",
    "    while sample_token:\n",
    "        all_sample_tokens.append(sample_token)\n",
    "        sample = level5data.get(\"sample\", sample_token)\n",
    "        sample_token = sample[\"next\"]\n",
    "        i += 1\n",
    "    scene_len.append(i)\n",
    "#     print(len(all_sample_tokens[-1]))\n",
    "    \n",
    "print('Total number of tokens=',len(all_sample_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "class BEVImageTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sample_tokens, data_folder):\n",
    "        self.sample_tokens = sample_tokens\n",
    "        self.data_folder = data_folder\n",
    "    def __len__(self):\n",
    "        return len(self.sample_tokens)\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample_token = self.sample_tokens[idx]\n",
    "        input_filepath = os.path.join(self.data_folder,f\"{sample_token}_input.png\")\n",
    "        map_filepath = os.path.join(self.data_folder,f\"{sample_token}_map.png\")\n",
    "        \n",
    "        im = cv2.imread(input_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        m_im = cv2.imread(input_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        map_im = cv2.imread(map_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        m_im = np.concatenate((m_im, map_im), axis=2)\n",
    "        \n",
    "        im = im.astype(np.float32)/255\n",
    "        m_im = m_im.astype(np.float32)/255\n",
    "        im = torch.from_numpy(im.transpose(2,0,1))\n",
    "        m_im = torch.from_numpy(m_im.transpose(2,0,1))\n",
    "        \n",
    "        return im, m_im, sample_token\n",
    "\n",
    "test_data_folder = '/home/hsb2140/deep-learnging-3d-object-dectation/input/lyft3d-mask-test-data/test_data/test_data'\n",
    "\n",
    "test_dataset = BEVImageTestDataset(all_sample_tokens,test_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We weigh the loss for the 0 class lower to account for (some of) the big class imbalance.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_weights = torch.from_numpy(np.array([0.2] + [1.0]*len(classes), dtype=np.float32))\n",
    "class_weights = class_weights.to(device)\n",
    "print(np.array([1.0]*len(classes), dtype=np.float32))\n",
    "print(class_weights)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "net.eval();\n",
    "import gc\n",
    "gc.collect()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, num_workers=os.cpu_count()*2)\n",
    "progress_bar = tqdm_notebook(test_loader)\n",
    "\n",
    "# We quantize to uint8 here to conserve memory. We're allocating >20GB of memory otherwise.\n",
    "# predictions = np.zeros((len(test_loader), 1+len(classes), 336, 336), dtype=np.uint8)\n",
    "\n",
    "sample_tokens = []\n",
    "all_losses = []\n",
    "\n",
    "detection_boxes = []\n",
    "detection_scores = []\n",
    "detection_classes = []\n",
    "\n",
    "# Arbitrary threshold in our system to create a binary image to fit boxes around.\n",
    "background_threshold = 200\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ii, (X, X2, batch_sample_tokens) in enumerate(progress_bar):\n",
    "\n",
    "        sample_tokens.extend(batch_sample_tokens)\n",
    "        \n",
    "        X = X.to(device)  # [N, 1, H, W]\n",
    "        prediction = model(X, X2)  # [N, 2, H, W]\n",
    "        prediction = F.softmax(prediction, dim=1)\n",
    "        \n",
    "        prediction_cpu = prediction.cpu().numpy()\n",
    "        predictions = np.round(prediction_cpu*255).astype(np.uint8)\n",
    "        \n",
    "        # Get probabilities for non-background\n",
    "        predictions_non_class0 = 255 - predictions[:,0]\n",
    "        \n",
    "        predictions_opened = np.zeros((predictions_non_class0.shape), dtype=np.uint8)\n",
    "\n",
    "        for i, p in enumerate(predictions_non_class0):\n",
    "            thresholded_p = (p > background_threshold).astype(np.uint8)\n",
    "            predictions_opened[i] = cv2.morphologyEx(thresholded_p, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "            sample_boxes,sample_detection_scores,sample_detection_classes = calc_detection_box(predictions_opened[i],\n",
    "                                                                                              predictions[i])\n",
    "        \n",
    "            detection_boxes.append(np.array(sample_boxes))\n",
    "            detection_scores.append(sample_detection_scores)\n",
    "            detection_classes.append(sample_detection_classes)\n",
    "        \n",
    "#         # Visualize the first prediction\n",
    "#         if ii == 0:\n",
    "#             visualize_predictions(X, prediction, apply_softmaxiii=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total amount of boxes:\", np.sum([len(x) for x in detection_boxes]))\n",
    "    \n",
    "\n",
    "# Visualize the boxes in the first sample\n",
    "t = np.zeros_like(predictions_opened[0])\n",
    "for sample_boxes in detection_boxes[0]:\n",
    "    box_pix = np.int0(sample_boxes)\n",
    "    cv2.drawContours(t,[box_pix],0,(255),2)\n",
    "plt.imshow(t)\n",
    "plt.show()\n",
    "\n",
    "# Visualize their probabilities\n",
    "plt.hist(detection_scores[0], bins=20)\n",
    "plt.xlabel(\"Detection Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Camera of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/home/hsb2140/deep-learnging-3d-object-dectation/cam_viz',exist_ok=True)\n",
    " \n",
    "from lyft_dataset_sdk.eval.detection.mAP_evaluation import Box3D, recall_precision\n",
    "import shutil\n",
    "\n",
    "pred_box3ds = []\n",
    "\n",
    "max_frames = 128\n",
    "vid_count = 0\n",
    "processed_samples = 0\n",
    "for (sample_token, sample_boxes, sample_detection_scores, sample_detection_class) in tqdm_notebook(zip(sample_tokens, detection_boxes, detection_scores, detection_classes), total=len(sample_tokens)):\n",
    "    processed_samples += 1\n",
    "    sample_boxes = sample_boxes.reshape(-1, 2) # (N, 4, 2) -> (N*4, 2)\n",
    "    sample_boxes = sample_boxes.transpose(1,0) # (N*4, 2) -> (2, N*4)\n",
    "\n",
    "    # Add Z dimension\n",
    "    sample_boxes = np.vstack((sample_boxes, np.zeros(sample_boxes.shape[1]),)) # (2, N*4) -> (3, N*4)\n",
    "\n",
    "    sample = level5data.get(\"sample\", sample_token)\n",
    "    sample_lidar_token = sample[\"data\"][\"LIDAR_TOP\"]\n",
    "    lidar_data = level5data.get(\"sample_data\", sample_lidar_token)\n",
    "    lidar_filepath = level5data.get_sample_data_path(sample_lidar_token)\n",
    "    ego_pose = level5data.get(\"ego_pose\", lidar_data[\"ego_pose_token\"])\n",
    "    ego_translation = np.array(ego_pose['translation'])\n",
    "\n",
    "    global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                       Quaternion(ego_pose['rotation']), inverse=False)\n",
    "\n",
    "    car_from_voxel = np.linalg.inv(create_transformation_matrix_to_voxel_space(bev_shape, voxel_size, (0, 0, z_offset)))\n",
    "\n",
    "\n",
    "    global_from_voxel = np.dot(global_from_car, car_from_voxel)\n",
    "    sample_boxes = transform_points(sample_boxes, global_from_voxel)\n",
    "\n",
    "    # We don't know at where the boxes are in the scene on the z-axis (up-down), let's assume all of them are at\n",
    "    # the same height as the ego vehicle.\n",
    "    sample_boxes[2,:] = ego_pose[\"translation\"][2]\n",
    "\n",
    "\n",
    "    # (3, N*4) -> (N, 4, 3)\n",
    "    sample_boxes = sample_boxes.transpose(1,0).reshape(-1, 4, 3)\n",
    "\n",
    "#     box_height = 1.75\n",
    "    box_height = np.array([class_heights[cls] for cls in sample_detection_class])\n",
    "\n",
    "    # Note: Each of these boxes describes the ground corners of a 3D box.\n",
    "    # To get the center of the box in 3D, we'll have to add half the height to it.\n",
    "    sample_boxes_centers = sample_boxes.mean(axis=1)\n",
    "    sample_boxes_centers[:,2] += box_height/2\n",
    "\n",
    "    # Width and height is arbitrary - we don't know what way the vehicles are pointing from our prediction segmentation\n",
    "    # It doesn't matter for evaluation, so no need to worry about that here.\n",
    "    # Note: We scaled our targets to be 0.8 the actual size, we need to adjust for that\n",
    "    sample_lengths = np.linalg.norm(sample_boxes[:,0,:] - sample_boxes[:,1,:], axis=1) * 1/box_scale\n",
    "    sample_widths = np.linalg.norm(sample_boxes[:,1,:] - sample_boxes[:,2,:], axis=1) * 1/box_scale\n",
    "    \n",
    "    sample_boxes_dimensions = np.zeros_like(sample_boxes_centers) \n",
    "    sample_boxes_dimensions[:,0] = sample_widths\n",
    "    sample_boxes_dimensions[:,1] = sample_lengths\n",
    "    sample_boxes_dimensions[:,2] = box_height\n",
    "    \n",
    "    temp = []\n",
    "    for i in range(len(sample_boxes)):\n",
    "        translation = sample_boxes_centers[i]\n",
    "        size = sample_boxes_dimensions[i]\n",
    "        class_name = sample_detection_class[i]\n",
    "        ego_distance = float(np.linalg.norm(ego_translation - translation))\n",
    "    \n",
    "        \n",
    "        # Determine the rotation of the box\n",
    "        v = (sample_boxes[i,0] - sample_boxes[i,1])\n",
    "        v /= np.linalg.norm(v)\n",
    "        r = R.from_dcm([\n",
    "            [v[0], -v[1], 0],\n",
    "            [v[1],  v[0], 0],\n",
    "            [   0,     0, 1],\n",
    "        ])\n",
    "        quat = r.as_quat()\n",
    "        # XYZW -> WXYZ order of elements\n",
    "        quat = quat[[3,0,1,2]]\n",
    "        \n",
    "        detection_score = float(sample_detection_scores[i])\n",
    "\n",
    "        \n",
    "        box3d = Box(\n",
    "            token=sample_token,\n",
    "            center=list(translation),\n",
    "            size=list(size),\n",
    "            orientation=Quaternion(quat),\n",
    "            name=class_name,\n",
    "            score=detection_score\n",
    "        )\n",
    "        \n",
    "        temp.append(box3d)\n",
    "        box3d = Box3D(\n",
    "            sample_token=sample_token,\n",
    "            translation=list(translation),\n",
    "            size=list(size),\n",
    "            rotation=list(quat),\n",
    "            name=class_name,\n",
    "            score=detection_score\n",
    "        )\n",
    "        pred_box3ds.append(box3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = {}\n",
    "for i in tqdm_notebook(range(len(pred_box3ds))):\n",
    "    yaw = 2*np.arccos(pred_box3ds[i].rotation[0]);\n",
    "    pred =  str(pred_box3ds[i].score/255) + ' ' + str(pred_box3ds[i].center_x)  + ' '  + \\\n",
    "    str(pred_box3ds[i].center_y) + ' '  + str(pred_box3ds[i].center_z) + ' '  + \\\n",
    "    str(pred_box3ds[i].width) + ' ' \\\n",
    "    + str(pred_box3ds[i].length) + ' '  + str(pred_box3ds[i].height) + ' ' + str(yaw) + ' ' \\\n",
    "    + str(pred_box3ds[i].name) + ' ' \n",
    "        \n",
    "    if pred_box3ds[i].sample_token in sub.keys():     \n",
    "        sub[pred_box3ds[i].sample_token] += pred\n",
    "    else:\n",
    "        sub[pred_box3ds[i].sample_token] = pred        \n",
    "    \n",
    "sample_sub = pd.read_csv('/home/ys3152/sample_submission.csv')\n",
    "for token in set(sample_sub.Id.values).difference(sub.keys()):\n",
    "    sub[token] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(list(sub.items()))\n",
    "sub.columns = sample_sub.columns\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('/home/hsb2140/lyft3d_pred_pspnet_unet_mean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
